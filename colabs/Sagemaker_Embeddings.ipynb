{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/withpi/cookbook-withpi/blob/main/colabs/Sagemaker_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://withpi.ai\"><img src=\"https://withpi.ai/logo/logoFullBlack.svg\" width=\"240px\"></a>\n",
        "\n",
        "<a href=\"https://code.withpi.ai\"><font size=\"4\">Documentation</font></a>\n",
        "\n",
        "<a href=\"https://withpi.ai\"><font size=\"4\">Copilot</font></a>"
      ],
      "metadata": {
        "id": "Th0kWr38rG1j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embeddings\n",
        "\n",
        "Pi has published its Pi Embedding model for deployment on AWS Sagemaker.\n",
        "\n",
        "It takes as input a list of items to embed and returns a list of embeddings.\n",
        "\n",
        "Deploy to Sagemaker for inference in your own AWS account.  This notebook shows how to perform inference with it.\n",
        "\n",
        "You will need appropriate secrets in your notebook to access your account, such as `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY` and `AWS_SESSION_TOKEN`.  When running locally authenticate to AWS in the normal manner.\n",
        "\n",
        "Start by installing packages and adding environment variables."
      ],
      "metadata": {
        "id": "S7uqCaRarJg7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbxkKAn8Us-1",
        "outputId": "73cc9807-6caa-4f8f-d3b5-94c4fb12f2c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting boto3\n",
            "  Downloading boto3-1.40.9-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Collecting botocore<1.41.0,>=1.40.9 (from boto3)\n",
            "  Downloading botocore-1.40.9-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3)\n",
            "  Downloading s3transfer-0.13.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore<1.41.0,>=1.40.9->boto3) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<1.41.0,>=1.40.9->boto3) (2.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.9->boto3) (1.17.0)\n",
            "Downloading boto3-1.40.9-py3-none-any.whl (140 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.1/140.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.40.9-py3-none-any.whl (14.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.13.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.40.9 botocore-1.40.9 jmespath-1.0.1 s3transfer-0.13.1\n"
          ]
        }
      ],
      "source": [
        "%pip install boto3 tqdm\n",
        "\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"AWS_ACCESS_KEY_ID\"] = userdata.get('AWS_ACCESS_KEY_ID')\n",
        "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = userdata.get(\"AWS_SECRET_ACCESS_KEY\")\n",
        "os.environ[\"AWS_SESSION_TOKEN\"] = userdata.get(\"AWS_SESSION_TOKEN\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample inference\n",
        "\n",
        "Run the below cell to test if everything is working.\n",
        "\n",
        "You will need to plug in the name of your Sagemaker endpoint and the region it is located in below."
      ],
      "metadata": {
        "id": "O4_U2rvH3xaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "import json\n",
        "import time\n",
        "\n",
        "# Initialize the SageMaker runtime client\n",
        "# Update the region if needed\n",
        "sagemaker_runtime = boto3.client('sagemaker-runtime', region_name='us-east-1')\n",
        "\n",
        "# Your endpoint configuration\n",
        "endpoint_name = 'MarketplaceEndpoint'\n",
        "\n",
        "latencies = []\n",
        "for _ in range(10):\n",
        "  start = time.perf_counter()\n",
        "  response = sagemaker_runtime.invoke_endpoint(\n",
        "      EndpointName=endpoint_name,\n",
        "      ContentType='application/json',\n",
        "      Body=json.dumps({\"query\": [\"A document to embed\"], \"batch\": False})\n",
        "  )\n",
        "  stop = time.perf_counter()\n",
        "  latencies.append(f\"{stop-start:.3f}\")\n",
        "\n",
        "print(f\"Latencies: {latencies}\")\n",
        "results = json.loads(response['Body'].read().decode())\n",
        "display(\"Retrieved embeddings\")\n",
        "display(f\"Sample dimensions: {results[0][:5]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "nJskVOdtvV1-",
        "outputId": "fb046a57-a558-4d54-e76a-aeaeee5dc79d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latencies: ['0.149', '0.130', '0.137', '0.165', '0.157', '0.158', '0.170', '0.168', '0.153', '0.162']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Retrieved embeddings'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Sample dimensions: [-0.11114501953125, 0.0201416015625, -0.031494140625, -0.038177490234375, 0.016082763671875]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load test\n",
        "\n",
        "The cell below will hit the endpoint with a lot of batch traffic to demonstrate throughput.  Use this to compute how many instances you need for anticipated traffic."
      ],
      "metadata": {
        "id": "KzD09YtmdCiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "num_terms = 1024\n",
        "batch_size = 16\n",
        "max_concurrency = 16\n",
        "num_batches=1000\n",
        "\n",
        "large_payload = {\n",
        "    \"query\": [\n",
        "        \" \".join([\"term\"]*num_terms)\n",
        "    ]*batch_size,\n",
        "    \"batch\": True\n",
        "}\n",
        "\n",
        "def make_call():\n",
        "  response = sagemaker_runtime.invoke_endpoint(\n",
        "      EndpointName=endpoint_name,\n",
        "      ContentType='application/json',\n",
        "      Body=json.dumps(large_payload)\n",
        "  )\n",
        "  return response\n",
        "\n",
        "\n",
        "start = time.perf_counter()\n",
        "with ThreadPoolExecutor(max_workers=max_concurrency) as executor:\n",
        "  futures = [executor.submit(make_call) for _ in range(num_batches)]\n",
        "  for future in tqdm(as_completed(futures), total=len(futures)):\n",
        "    # Will throw on error to abort the test\n",
        "    result = future.result()\n",
        "stop = time.perf_counter()\n",
        "\n",
        "elapsed = stop-start\n",
        "total_embedded = num_terms*batch_size*num_batches\n",
        "\n",
        "display(f\"Total terms embedded: {total_embedded}\")\n",
        "display(f\"Elapsed time: {elapsed:.2f} seconds\")\n",
        "display(f\"Throughput: {total_embedded / elapsed:.2f} tokens/second\")"
      ],
      "metadata": {
        "id": "zg3jSa-ado04",
        "outputId": "87b080e4-67b5-47cf-85f3-858ad4f2f19d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [02:16<00:00,  7.35it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Total terms embedded: 16384000'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Elapsed time: 137.20 seconds'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Throughput: 119417.21 tokens/second'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}