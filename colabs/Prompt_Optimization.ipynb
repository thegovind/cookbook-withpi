{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/withpi/cookbook-withpi/blob/main/colabs/Prompt_Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WithPi Prompt Optimization\n",
        "\n",
        "This colab assumes that you already went through [Input Generation](https://colab.research.google.com/github/withpi/cookbook-withpi/blob/main/colabs/Input_Generation.ipynb), and now wish to optimize your system prompt\n",
        "\n",
        "We will walk through the same `Aesop AI` example, but you can load any contract here. Let's dig in!\n",
        "\n",
        "This should take about **15 minutes**, even if you're unfamiliar with Colab."
      ],
      "metadata": {
        "id": "Bwm4tjdnedp6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install and initialize SDK\n",
        "\n",
        "Connect to a regular CPU Python 3 runtime.  You won't need GPUs for this notebook.\n",
        "\n",
        "You'll need a WITHPI_API_KEY from https://play.withpi.ai.  Add it to your notebook secrets (the key symbol) on the left.\n",
        "\n",
        "Run the cell below to install packages and load the SDK"
      ],
      "metadata": {
        "id": "9HBxNR2oerzC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXIRVg-sMv-S"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "%pip install withpi httpx pandas\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from withpi import PiClient\n",
        "\n",
        "os.environ[\"WITHPI_API_KEY\"] = userdata.get('WITHPI_API_KEY')\n",
        "\n",
        "client = PiClient()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load contract and Dataset\n",
        "\n",
        "Load the `Aesop AI` example and example set from Pi Labs cookbooks, or edit below to load a different one.\n"
      ],
      "metadata": {
        "id": "s7RRO3iXjYbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import httpx\n",
        "import pandas as pd\n",
        "from google.colab import data_table\n",
        "from withpi.types import Contract\n",
        "\n",
        "resp = httpx.get(\"https://raw.githubusercontent.com/withpi/cookbook-withpi/refs/heads/main/contracts/aesop_ai.json\")\n",
        "\n",
        "aesop_contract = Contract.model_validate_json(resp.content)\n",
        "\n",
        "for dimension in aesop_contract.dimensions:\n",
        "  print(dimension.label)\n",
        "  for sub_dimension in dimension.sub_dimensions:\n",
        "    print(f\"\\t{sub_dimension.description}\")\n",
        "\n",
        "df = pd.read_parquet(\"https://raw.githubusercontent.com/withpi/cookbook-withpi/refs/heads/main/datasets/aesop_ai_examples.parquet\")\n",
        "data_table.enable_dataframe_formatter()\n",
        "df\n"
      ],
      "metadata": {
        "id": "oXJmb89i5iN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimize your prompt\n",
        "\n",
        "Kick off a prompt optimization run.  This will operate in the background."
      ],
      "metadata": {
        "id": "j1FAoBqU7dwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_optimization_status = client.prompt.optimize(\n",
        "    contract=aesop_contract,\n",
        "    dspy_optimization_type=\"COPRO\",\n",
        "    examples=[{\"llm_input\": row[\"input\"], \"llm_output\": row[\"output\"]} for index, row in df.iterrows()],\n",
        "    initial_system_instruction=aesop_contract.description,\n",
        "    model_id=\"gpt-4o-mini\",\n",
        "    tuning_algorithm=\"DSPY\",\n",
        ")"
      ],
      "metadata": {
        "id": "4NpCZhP6exgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check for completion\n",
        "\n",
        "The following cell will connect to the tail of logs while optimization proceeds.  It will take order of **10 minutes**"
      ],
      "metadata": {
        "id": "FYT2a6-7zHVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  optimized_response = client.prompt.get_status(job_id=prompt_optimization_status.job_id)\n",
        "  if (optimized_response.state != 'QUEUED') and (optimized_response.state != 'RUNNING'):\n",
        "    break\n",
        "\n",
        "  with client.prompt.with_streaming_response.stream_messages(\n",
        "      job_id=prompt_optimization_status.job_id, timeout=None) as response:\n",
        "    for line in response.iter_lines():\n",
        "          print(line)\n",
        "\n",
        "display(optimized_response.optimized_prompt_messages)"
      ],
      "metadata": {
        "id": "01LXvjOMte7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the new system prompt template\n",
        "\n",
        "It's convenient to stash this template for use later."
      ],
      "metadata": {
        "id": "rMTmieU9xPgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "\n",
        "filename = 'aesop_ai_dspy_prompt.json'\n",
        "Path(filename).write_text(json.dumps(optimized_response.optimized_prompt_messages, indent=2))\n",
        "files.download(filename)"
      ],
      "metadata": {
        "id": "tpWpFWfEwo4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next Steps\n",
        "\n",
        "Now that you have an improved prompt using an **uncalibrated** contract, let's try **calibrating** the contract!  This should help it more closely align with what you actually value.  Proceed on to the [Contract Calibration](https://colab.research.google.com/github/withpi/cookbook-withpi/blob/main/colabs/Contract_Calibration.ipynb) colab to do this."
      ],
      "metadata": {
        "id": "jT7s_nuJsHbM"
      }
    }
  ]
}