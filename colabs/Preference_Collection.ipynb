{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/withpi/cookbook-withpi/blob/main/colabs/Preference_Collection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://withpi.ai\"><img src=\"https://withpi.ai/logoFullBlack.svg\" width=\"240\"></a>\n",
        "\n",
        "<a href=\"https://code.withpi.ai\"><font size=\"4\">Documentation</font></a>\n",
        "\n",
        "<a href=\"https://play.withpi.ai\"><font size=\"4\">Technique Catalog</font></a>"
      ],
      "metadata": {
        "id": "pi-masthead"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bwm4tjdnedp6"
      },
      "source": [
        "# Preference Collection\n",
        "\n",
        "This Colab is the companion to the Preference Collection Playground, showing how you can apply preference datat to your training pipeline.\n",
        "\n",
        "It's easier to collect training data from the UI, but this Colab will have you rate a small number of examples in-line.\n",
        "\n",
        "We will walk through the same `Aesop AI` example, but any contract with feedback data should work."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install and initialize SDK\n",
        "\n",
        "Connect to a regular CPU Python 3 runtime.  You won't need GPUs for this notebook.\n",
        "\n",
        "You'll need a WITHPI_API_KEY from https://play.withpi.ai.  Add it to your notebook secrets (the key symbol) on the left.\n",
        "\n",
        "Run the cell below to install packages and load the SDK"
      ],
      "metadata": {
        "id": "pi-setup-markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi-setup"
      },
      "outputs": [],
      "execution_count": null,
      "source": [
        "%%capture\n",
        "\n",
        "import os\n",
        "from google.colab import files, userdata\n",
        "\n",
        "# Load the notebook secret into the environment so the Pi Client can access it.\n",
        "os.environ[\"WITHPI_API_KEY\"] = userdata.get('WITHPI_API_KEY')\n",
        "\n",
        "%pip install withpi litellm httpx datasets jinja2 tqdm\n",
        "\n",
        "# Import a bunch of useful libraries for later.\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from collections import defaultdict\n",
        "import time\n",
        "import json\n",
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "import datasets\n",
        "import httpx\n",
        "import litellm\n",
        "import jinja2\n",
        "from tqdm.notebook import tqdm\n",
        "from withpi import PiClient\n",
        "from withpi.types import Contract\n",
        "\n",
        "from rich.console import Console\n",
        "from rich.table import Table\n",
        "from rich.live import Live\n",
        "\n",
        "console = Console()\n",
        "\n",
        "client = PiClient()\n",
        "\n",
        "def print_contract(contract: Contract):\n",
        "  \"\"\"print_contract pretty-prints a contract\"\"\"\n",
        "  for dimension in contract.dimensions:\n",
        "    print(dimension.label)\n",
        "    for sub_dimension in dimension.sub_dimensions:\n",
        "      print(f\"\\t{sub_dimension.description}\")\n",
        "\n",
        "def generate(system: str, user: str, model: str) -> str:\n",
        "  \"\"\"generate passes the provided system and user prompts into the given model\n",
        "  via LiteLLM\"\"\"\n",
        "  messages = [\n",
        "    {\n",
        "      \"content\": system,\n",
        "      \"role\": \"system\"\n",
        "    },\n",
        "    {\n",
        "      \"content\": user,\n",
        "      \"role\": \"user\"\n",
        "    }\n",
        "  ]\n",
        "  return litellm.completion(model=model,\n",
        "                            messages=messages).choices[0].message.content\n",
        "\n",
        "class printer(str):\n",
        "  \"\"\"printer makes strings with embedded newlines print more nicely\"\"\"\n",
        "  def __repr__(self):\n",
        "    return self\n",
        "def print_response(response: str):\n",
        "  \"\"\"print_response pretty-prints an LLM response, respecting newlines\"\"\"\n",
        "  display(printer(response))\n",
        "\n",
        "def print_scores(pi_scores):\n",
        "  \"\"\"print_scores pretty-prints a Pi Score response as a table.\"\"\"\n",
        "  for dimension_name, dimension_scores in pi_scores.dimension_scores.items():\n",
        "    print(f\"{dimension_name}: {dimension_scores.total_score}\")\n",
        "    for subdimension_name, subdimension_score in dimension_scores.subdimension_scores.items():\n",
        "      print(f\"\\t{subdimension_name}: {subdimension_score}\")\n",
        "    print(\"\\n\")\n",
        "  print(\"---------------------\")\n",
        "  print(f\"Total score: {pi_scores.total_score}\")\n",
        "\n",
        "def save_file(filename: str, model: str):\n",
        "  \"\"\"save_file offers to download the model with the given filename\"\"\"\n",
        "  Path(filename).write_text(model)\n",
        "  files.download(filename)\n",
        "\n",
        "def load_contract(url: str) -> Contract:\n",
        "  \"\"\"load_contract pulls a Contract JSON blob locally with validation.\"\"\"\n",
        "  resp = httpx.get(url)\n",
        "  return Contract.model_validate_json(resp.content)\n",
        "\n",
        "def load_and_split_dataset(url: str) -> datasets.DatasetDict:\n",
        "  \"\"\"load_and_split_dataset pulls in the Parquet file at url and does a 90/10 split\"\"\"\n",
        "  return datasets.load_dataset('parquet', data_files=url, split=\"train\").train_test_split(test_size=0.1)\n",
        "\n",
        "def do_bulk_inference(dataset, system, model):\n",
        "  \"\"\"do_bulk_inference performs inference on the 'input' column of dataset, using\n",
        "  the provided system prompt.  The model identified will be used via LiteLLM\"\"\"\n",
        "\n",
        "  def do_generate(user, pbar):\n",
        "    result = generate(system, user, model)\n",
        "    pbar.update(1)\n",
        "    return result\n",
        "\n",
        "  futures = []\n",
        "  pbar = tqdm(total=len(dataset))\n",
        "  with ThreadPoolExecutor(max_workers=4) as executor:\n",
        "    for row in dataset:\n",
        "      futures.append(executor.submit(do_generate, row[\"input\"], pbar))\n",
        "  return [future.result() for future in futures]\n",
        "\n",
        "def do_bulk_templated_inference(dataset, optimized, model):\n",
        "  \"\"\"do_bulk_templated_inference performs inference on the 'input' column of dataset,\n",
        "  using the provided optimized prompt.  It should be a Jinja2 template as returned\n",
        "  by DSPy\"\"\"\n",
        "  prompt_template = jinja2.Template(optimized)\n",
        "  result_extractor = re.compile(r\".*\\[\\[ ## response ## \\]\\](.*)\\[\\[ ## completed ## \\]\\]\", re.DOTALL)\n",
        "\n",
        "  def do_generate(prompt: str, pbar) -> str:\n",
        "    messages = json.loads(prompt_template.render(input=prompt))\n",
        "    result = litellm.completion(model=model,\n",
        "                                messages=messages).choices[0].message.content\n",
        "\n",
        "    pbar.update(1)\n",
        "    return result_extractor.match(result).group(1)\n",
        "\n",
        "  futures = []\n",
        "  pbar = tqdm(total=len(dataset))\n",
        "  with ThreadPoolExecutor(max_workers=4) as executor:\n",
        "    for row in dataset:\n",
        "      futures.append(executor.submit(do_generate, row[\"input\"], pbar))\n",
        "  return [future.result() for future in futures]\n",
        "\n",
        "def generate_table(\n",
        "    job_id: str, training_data: dict, is_done: bool, additional_columns: dict[str, str]\n",
        "):\n",
        "    \"\"\"Generate a training progress table dynamically.\"\"\"\n",
        "    table = Table(title=f\"Training Status for {job_id}\")\n",
        "\n",
        "    # Define columns\n",
        "    table.add_column(\"Step\", justify=\"right\", style=\"cyan\")\n",
        "    table.add_column(\"Epoch\", justify=\"right\", style=\"cyan\")\n",
        "    table.add_column(\"Learning Rate\", justify=\"right\", style=\"cyan\")\n",
        "    table.add_column(\"Train Loss\", justify=\"right\", style=\"magenta\")\n",
        "    table.add_column(\"Eval Loss\", justify=\"right\", style=\"green\")\n",
        "    for header in additional_columns.keys():\n",
        "        table.add_column(header, justify=\"right\", style=\"black\")\n",
        "\n",
        "    def format_num(num: float | None, digits: int = 4) -> str:\n",
        "        if num is None:\n",
        "            return \"X\"\n",
        "        return format(num, f\".{digits}f\")\n",
        "\n",
        "    for step, data in training_data.items():\n",
        "        additional_columns_data = [\n",
        "            format_num(data.get(column_name, None))\n",
        "            for column_name in additional_columns.values()\n",
        "        ]\n",
        "        table.add_row(\n",
        "            str(step),\n",
        "            format_num(data.get(\"epoch\", None)),\n",
        "            format_num(data.get(\"learning_rate\", None), digits=10),\n",
        "            format_num(data.get(\"loss\", None)),\n",
        "            format_num(data.get(\"eval_loss\", None)),\n",
        "            *additional_columns_data,\n",
        "        )\n",
        "\n",
        "    if not is_done:\n",
        "        table.add_row(\"...\", \"\", \"\", \"\", \"\", \"\")\n",
        "\n",
        "    return table\n",
        "\n",
        "\n",
        "def stream_response(job_id: str, method, additional_columns: dict[str, str]):\n",
        "    \"\"\"stream_response streams messages from the provided method\n",
        "\n",
        "    method should be a Pi client object with `retrieve` and `stream_messages`\n",
        "    endpoints.  This is primarily for convenience.\"\"\"\n",
        "\n",
        "    training_data = defaultdict(dict)\n",
        "    is_log_console = False\n",
        "\n",
        "    while True:\n",
        "        response = method.retrieve(job_id=job_id)\n",
        "        if (response.state != \"QUEUED\") and (response.state != \"RUNNING\"):\n",
        "            if response.state == \"DONE\" and not is_log_console:\n",
        "                for line in response.detailed_status:\n",
        "                    try:\n",
        "                        data_dict = json.loads(line)\n",
        "                        training_data[data_dict[\"step\"]].update(data_dict)\n",
        "                    except Exception:\n",
        "                        pass\n",
        "                console.print(\n",
        "                    generate_table(\n",
        "                        job_id,\n",
        "                        training_data,\n",
        "                        is_done=True,\n",
        "                        additional_columns=additional_columns,\n",
        "                    )\n",
        "                )\n",
        "            return response\n",
        "\n",
        "        with method.with_streaming_response.stream_messages(\n",
        "            job_id=job_id, timeout=None\n",
        "        ) as response:\n",
        "            with Live(auto_refresh=True, console=console, refresh_per_second=4) as live:\n",
        "                is_done = False\n",
        "                for line in response.iter_lines():\n",
        "                    if line == \"DONE\":\n",
        "                        is_done = True\n",
        "                    try:\n",
        "                        data_dict = json.loads(line)\n",
        "                        training_data[data_dict[\"step\"]].update(data_dict)\n",
        "                    except Exception:\n",
        "                        pass\n",
        "                    live.update(\n",
        "                        generate_table(\n",
        "                            job_id,\n",
        "                            training_data,\n",
        "                            is_done,\n",
        "                            additional_columns=additional_columns,\n",
        "                        )\n",
        "                    )\n",
        "                    is_log_console = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load contract and Dataset\n",
        "\n",
        "Load the contract and example data.  The examples are stored on Pi's repository, but you can easily load any Hugging Face dataset with this library."
      ],
      "metadata": {
        "id": "HVdupu3M5t8x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXJmb89i5iN5"
      },
      "outputs": [],
      "source": [
        "aesop_contract = load_contract(\"https://raw.githubusercontent.com/withpi/cookbook-withpi/refs/heads/main/contracts/aesop_ai.json\")\n",
        "aesop = load_and_split_dataset(\"https://raw.githubusercontent.com/withpi/cookbook-withpi/refs/heads/main/datasets/aesop_ai_examples.parquet\")\n",
        "aesop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1FAoBqU7dwf"
      },
      "source": [
        "## Cluster Inputs\n",
        "\n",
        "We're going to label some inputs as \"good\" and \"bad\", but to do this it is helpful to focus on a few different types of input.  We'll use clustering to make sure we don't have to look at too many examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NpCZhP6exgI"
      },
      "outputs": [],
      "source": [
        "input_topic_clusters = client.data.inputs.cluster(\n",
        "    inputs=[{\"identifier\": str(index), \"llm_input\": row[\"input\"]} for index, row in enumerate(aesop['train'])],\n",
        ")\n",
        "\n",
        "cluster_column = ['']*len(aesop['train'])\n",
        "for cluster in input_topic_clusters:\n",
        "  print(f\"{cluster.topic}: {len(cluster.inputs)}\")\n",
        "  for identifier in cluster.inputs:\n",
        "    cluster_column[int(identifier)] = cluster.topic\n",
        "\n",
        "clustered_aesop = aesop['train'].add_column('cluster', cluster_column)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCHE6g_OCqCD"
      },
      "source": [
        "## Identify outliers\n",
        "\n",
        "Let's first score every input against the contract, adding that as a column.  Pi scoring is fast enough that serially processing the dataset is fine, though we could increase parallelism for more speed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57EujAhfC_qz"
      },
      "outputs": [],
      "source": [
        "aesop_scored = clustered_aesop.add_column(\"uncalibrated_scores\",\n",
        "   [client.contracts.score(contract=aesop_contract, llm_input=row[\"input\"], llm_output=row[\"output\"]).total_score for row in clustered_aesop]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMTmieU9xPgT"
      },
      "source": [
        "## Label data\n",
        "\n",
        "Now it's time to label examples against a simple statement.  **The response fully satisfies the input according to the contract**.  Valid responses are **Strongly Agree**, **Agree**, **Neutral**, **Disagree**, and **Strongly Disagree**, or simply **5** down to **1**.\n",
        "\n",
        "The below cell will select a high and low scoring exemplar from each cluster, asking you to respond **5** through **1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdaF7pnIGYxa"
      },
      "outputs": [],
      "source": [
        "def get_label(row):\n",
        "  display(\"Input Prompt:\")\n",
        "  display(row[\"input\"])\n",
        "  display(\"Output Response:\")\n",
        "  display(row[\"output\"])\n",
        "  while True:\n",
        "    resp = input(\"Your rating from 1 to 5: \")\n",
        "    try:\n",
        "      if int(resp) not in [1,2,3,4,5]:\n",
        "        raise ValueError(\"Invalid\")\n",
        "    except:\n",
        "      display(\"Invalid input. Try again\")\n",
        "      continue\n",
        "    break\n",
        "  row['label'] = resp\n",
        "  return row\n",
        "\n",
        "cluster_labels = set([x for x in aesop_scored[\"cluster\"]])\n",
        "labelled = []\n",
        "for cluster in cluster_labels:\n",
        "  sorted = aesop_scored.filter(lambda e: e['cluster'] == cluster).sort(\"uncalibrated_scores\")\n",
        "  labelled.append(get_label(sorted[0]))\n",
        "  labelled.append(get_label(sorted[-1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR-YSyrYM4-z"
      },
      "source": [
        "## Calibrate\n",
        "\n",
        "Now it's time to calibrate with the labelled sets.  The following cell will launch a job and monitor for completion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-4aZQ4YM9FL"
      },
      "outputs": [],
      "source": [
        "def to_rating(label):\n",
        "  match label:\n",
        "    case '1':\n",
        "      return \"Strongly Disagree\"\n",
        "    case '2':\n",
        "      return \"Disagree\"\n",
        "    case '3':\n",
        "      return \"Neutral\"\n",
        "    case '4':\n",
        "      return \"Agree\"\n",
        "    case '5':\n",
        "      return \"Strongly Agree\"\n",
        "\n",
        "contract_calibration_status = client.contracts.calibrate.start_job(\n",
        "    contract=aesop_contract,\n",
        "    examples=[{\"llm_input\": row['input'], \"llm_output\": row['output'], \"rating\": to_rating(row['label'])} for row in labelled]\n",
        ")\n",
        "aesop_contract_calibrated = stream_response(contract_calibration_status.job_id, client.contracts.calibrate).calibrated_contract"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mn4kg54Yixzn"
      },
      "source": [
        "## Rescore after calibration\n",
        "\n",
        "Now add a new column with calibrated scores. You can examine these to see if they more closely align with the examples you labelled.  Ideally the score starts separating good responses from bad.\n",
        "\n",
        "If it does not, that suggests the properties you **really** care about aren't captured in your scoring dimensions and will need to be added.  Proceed to the playgrounds at http://play.withpi.ai to experiment with this.\n",
        "\n",
        "If this is looking good, you have a powerful function for improving your system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cxd-uOBaOQQh"
      },
      "outputs": [],
      "source": [
        "for row in labelled:\n",
        "   row['calibrated'] = client.contracts.score(contract=aesop_contract_calibrated, llm_input=row[\"input\"], llm_output=row[\"output\"]).total_score\n",
        "   print(f\"Label: {row['label']}, Original Score: {row['uncalibrated_scores']}, Calibrated: {row['calibrated']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAaeXLrijCrK"
      },
      "source": [
        "## Save calibrated contract\n",
        "\n",
        "The updated contract now has different weights assigned to its dimensions.  Save those for later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpWpFWfEwo4j"
      },
      "outputs": [],
      "source": [
        "save_file('aesop_ai_calibrated.json', aesop_contract_calibrated.model_dump_json(indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jT7s_nuJsHbM"
      },
      "source": [
        "## Next Steps\n",
        "\n",
        "Now that you have a calibrated contract, other parts of Pi should work better.  This Colab used a limited amount of hand-labeled data, but scaling up this feedback loop will pay dividends."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}