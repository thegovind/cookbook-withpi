{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/withpi/cookbook-withpi/blob/main/colabs/PiScorer_as_GRPO_Reward_Function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pi-masthead"
      },
      "source": [
        "<a href=\"https://withpi.ai\"><img src=\"https://play.withpi.ai/logo/logoFullBlack.svg\" width=\"240\"></a>\n",
        "\n",
        "<a href=\"https://code.withpi.ai\"><font size=\"4\">Documentation</font></a>\n",
        "\n",
        "<a href=\"https://build.withpi.ai\"><font size=\"4\">Copilot</font></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiS-7CbBYS0D"
      },
      "source": [
        "Are you constantly relying on LLM-as-a-judge to evaluate your model’s performance?\n",
        "\n",
        "Have you ever wanted to assess your model at every training checkpoint but hesitated because LLM-as-a-judge is too slow and expensive?\n",
        "\n",
        "**Now you can — with [Pi-Scorer](https://build.withpi.ai).**\n",
        "\n",
        "[Pi-Scorer](https://build.withpi.ai) offers an alternative to LLM-as-a-judge with several advantages:\n",
        "\n",
        "* Significantly faster\n",
        "\n",
        "* Highly consistent — always returns the same score for the same inputs\n",
        "\n",
        "* Eliminates the need for prompt tuning or adjustments\n",
        "\n",
        "In this colab, we use Pi-Scorer as the reward function in the [Unsloth](https://unsloth.ai/) GRPO training loop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVoflExGYvu6"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuA79HQOBfWX"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Get PI API key: https://build.withpi.ai/account/keys\n",
        "os.environ[\"WITHPI_API_KEY\"] = userdata.get('WITHPI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfP5p84HYvu6"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth vllm\n",
        "else:\n",
        "    # [NOTE] Do the below ONLY in Colab! Use [[pip install unsloth vllm]]\n",
        "    !pip install --no-deps unsloth vllm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aC-VIBYpYvu6"
      },
      "outputs": [],
      "source": [
        "#@title Colab Extra Install { display-mode: \"form\" }\n",
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth vllm\n",
        "else:\n",
        "    !pip install --no-deps unsloth vllm\n",
        "    # [NOTE] Do the below ONLY in Colab! Use [[pip install unsloth vllm]]\n",
        "    # Skip restarting message in Colab\n",
        "    import sys, re, requests; modules = list(sys.modules.keys())\n",
        "    for x in modules: sys.modules.pop(x) if \"PIL\" in x or \"google\" in x else None\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft \"trl==0.15.2\" triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "\n",
        "    # vLLM requirements - vLLM breaks Colab due to reinstalling numpy\n",
        "    f = requests.get(\"https://raw.githubusercontent.com/vllm-project/vllm/refs/heads/main/requirements/common.txt\").content\n",
        "    with open(\"vllm_requirements.txt\", \"wb\") as file:\n",
        "        file.write(re.sub(rb\"(transformers|numpy|xformers)[^\\n]{1,}\\n\", b\"\", f))\n",
        "    !pip install -r vllm_requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kisw2lPYvu6"
      },
      "source": [
        "### Load Unsloth Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Joje4qPsyxM9"
      },
      "source": [
        "Load up `Qwen 2.5 3B Instruct`, and set parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkIvEkIIkEyB"
      },
      "outputs": [],
      "source": [
        "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
        "import torch\n",
        "max_seq_length = 1024 # Can increase for longer reasoning traces\n",
        "lora_rank = 64 # Larger rank = smarter, but slower\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"Qwen/Qwen2.5-3B-Instruct\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    load_in_4bit = True, # False for LoRA 16bit\n",
        "    fast_inference = True, # Enable vLLM fast inference\n",
        "    max_lora_rank = lora_rank,\n",
        "    gpu_memory_utilization = 0.5, # Reduce if out of memory\n",
        ")\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = lora_rank, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\n",
        "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
        "    ], # Remove QKVO if out of memory\n",
        "    lora_alpha = lora_rank,\n",
        "    use_gradient_checkpointing = \"unsloth\", # Enable long context finetuning\n",
        "    random_state = 3407,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Y56ln_izS9E"
      },
      "source": [
        "### Data Preparation and PI Reward Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXk993X6C2ZZ"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, Dataset\n",
        "import requests\n",
        "\n",
        "# Load and prep dataset\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "Generate a short TLDR of a subreddit post without any surrounding text. Here are some requirement of the TLDR:\n",
        "1. Make sure that the TLDR is short and concise.\n",
        "2. Make sure that the TLDR state the important points of the post\n",
        "3. Make sure that the TLDR should make sense on its own.\n",
        "\"\"\"\n",
        "\n",
        "dataset = load_dataset(\"trl-lib/tldr\", split=\"train\")\n",
        "dataset = dataset.remove_columns([\"completion\"])\n",
        "dataset = dataset.rename_column(\"prompt\", \"post\")\n",
        "dataset = dataset.select(range(500))\n",
        "dataset = dataset.map(\n",
        "    lambda x: {\n",
        "        \"prompt\": [\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "            {\"role\": \"user\", \"content\": x[\"post\"]},\n",
        "        ]\n",
        "    }\n",
        ")\n",
        "print(dataset[0])\n",
        "\n",
        "\n",
        "# Pi constants\n",
        "PI_API_URL = \"https://api.withpi.ai/v1/scoring_system/score\"\n",
        "HEADERS = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"x-api-key\": os.environ.get(\"WITHPI_API_KEY\"),\n",
        "}\n",
        "\n",
        "# Pi util functions\n",
        "def get_pi_score(input: str, output: str, question: str) -> float:\n",
        "    payload = {\n",
        "        \"llm_input\": input,\n",
        "        \"llm_output\": output,\n",
        "        \"scoring_spec\": [{\"question\": question}]\n",
        "    }\n",
        "    # Can add retry if needed.\n",
        "    response = requests.post(PI_API_URL, headers=HEADERS, json=payload)\n",
        "    return response.json()[\"total_score\"]\n",
        "\n",
        "def score_tldrs(prompts, completions, question: str) -> list[float]:\n",
        "    posts = [prompt[-1][\"content\"] for prompt in prompts]\n",
        "    tldrs = [completion[0][\"content\"] for completion in completions]\n",
        "    return [get_pi_score(post, tldr, question) for post, tldr in zip(posts, tldrs)]\n",
        "\n",
        "# Reward functions\n",
        "def pi_concise(prompts, completions, **kwargs) -> list[float]:\n",
        "    return score_tldrs(prompts, completions, \"Is the TLDR concise and to the point?\")\n",
        "\n",
        "def pi_coverage(prompts, completions, **kwargs) -> list[float]:\n",
        "    return score_tldrs(prompts, completions, \"Does the TLDR state the important points of the post?\")\n",
        "\n",
        "def pi_standalone(prompts, completions, **kwargs) -> list[float]:\n",
        "    return score_tldrs(prompts, completions, \"Does the TLDR make sense on its own without needing to refer to the original post?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTnL_tJnzh2L"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "\n",
        "Now set up GRPO Trainer and all configurations!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptqkXK2D4d6p",
        "outputId": "cbe61f7c-a68b-4c9f-af64-a754bb8f51fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.\n",
            "We will change the batch size of 1 to the `num_generations` of 8\n"
          ]
        }
      ],
      "source": [
        "from trl import GRPOConfig, GRPOTrainer\n",
        "training_args = GRPOConfig(\n",
        "    use_vllm = True, # use vLLM for fast inference!\n",
        "    learning_rate = 5e-6,\n",
        "    adam_beta1 = 0.9,\n",
        "    adam_beta2 = 0.99,\n",
        "    weight_decay = 0.1,\n",
        "    warmup_ratio = 0.1,\n",
        "    lr_scheduler_type = \"cosine\",\n",
        "    optim = \"adamw_8bit\",\n",
        "    logging_steps = 1,\n",
        "    bf16 = is_bfloat16_supported(),\n",
        "    fp16 = not is_bfloat16_supported(),\n",
        "    per_device_train_batch_size = 1,\n",
        "    gradient_accumulation_steps = 1, # Increase to 4 for smoother training\n",
        "    num_generations = 8, # Decrease if out of memory\n",
        "    max_prompt_length = 1024,\n",
        "    max_completion_length = 200,\n",
        "    # num_train_epochs = 1, # Set to 1 for a full training run\n",
        "    max_steps = 50,\n",
        "    save_steps = 50,\n",
        "    max_grad_norm = 0.1,\n",
        "    report_to = \"none\", # Can use Weights & Biases\n",
        "    output_dir = \"outputs\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vzOuSVCL_GA9",
        "outputId": "1830ba8c-ebd4-4a81-c3a1-8f3d33ba416f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 500 | Num Epochs = 1 | Total steps = 50\n",
            "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 1\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 1 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 119,734,272/3,000,000,000 (3.99% trained)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 13:55, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>reward</th>\n",
              "      <th>reward_std</th>\n",
              "      <th>completion_length</th>\n",
              "      <th>kl</th>\n",
              "      <th>rewards / pi_concise</th>\n",
              "      <th>rewards / pi_coverage</th>\n",
              "      <th>rewards / pi_standalone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.937163</td>\n",
              "      <td>1.245374</td>\n",
              "      <td>58.750000</td>\n",
              "      <td>0.000274</td>\n",
              "      <td>0.707291</td>\n",
              "      <td>0.619147</td>\n",
              "      <td>0.610725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.840332</td>\n",
              "      <td>0.165523</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>0.000096</td>\n",
              "      <td>0.983398</td>\n",
              "      <td>0.920410</td>\n",
              "      <td>0.936523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.833496</td>\n",
              "      <td>0.109911</td>\n",
              "      <td>53.625000</td>\n",
              "      <td>0.000172</td>\n",
              "      <td>0.988770</td>\n",
              "      <td>0.909668</td>\n",
              "      <td>0.935059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.684082</td>\n",
              "      <td>0.107859</td>\n",
              "      <td>74.125000</td>\n",
              "      <td>0.000144</td>\n",
              "      <td>0.987305</td>\n",
              "      <td>0.750488</td>\n",
              "      <td>0.946289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.820801</td>\n",
              "      <td>0.248008</td>\n",
              "      <td>59.875000</td>\n",
              "      <td>0.000115</td>\n",
              "      <td>0.989746</td>\n",
              "      <td>0.926758</td>\n",
              "      <td>0.904297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.874023</td>\n",
              "      <td>0.100043</td>\n",
              "      <td>63.375000</td>\n",
              "      <td>0.000267</td>\n",
              "      <td>0.991699</td>\n",
              "      <td>0.939453</td>\n",
              "      <td>0.942871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.675781</td>\n",
              "      <td>0.196436</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>0.001013</td>\n",
              "      <td>0.993652</td>\n",
              "      <td>0.754883</td>\n",
              "      <td>0.927246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.894043</td>\n",
              "      <td>0.108483</td>\n",
              "      <td>46.250000</td>\n",
              "      <td>0.000326</td>\n",
              "      <td>0.990723</td>\n",
              "      <td>0.976562</td>\n",
              "      <td>0.926758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.764648</td>\n",
              "      <td>0.271130</td>\n",
              "      <td>55.125000</td>\n",
              "      <td>0.001136</td>\n",
              "      <td>0.990723</td>\n",
              "      <td>0.884277</td>\n",
              "      <td>0.889648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.734375</td>\n",
              "      <td>0.160408</td>\n",
              "      <td>77.500000</td>\n",
              "      <td>0.001435</td>\n",
              "      <td>0.964355</td>\n",
              "      <td>0.860840</td>\n",
              "      <td>0.909180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.726074</td>\n",
              "      <td>0.079793</td>\n",
              "      <td>59.250000</td>\n",
              "      <td>0.001785</td>\n",
              "      <td>0.991699</td>\n",
              "      <td>0.791504</td>\n",
              "      <td>0.942871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.822754</td>\n",
              "      <td>0.146470</td>\n",
              "      <td>82.625000</td>\n",
              "      <td>0.001643</td>\n",
              "      <td>0.981445</td>\n",
              "      <td>0.950684</td>\n",
              "      <td>0.890625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.761230</td>\n",
              "      <td>0.105591</td>\n",
              "      <td>58.750000</td>\n",
              "      <td>0.002211</td>\n",
              "      <td>0.996094</td>\n",
              "      <td>0.832520</td>\n",
              "      <td>0.932617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.883301</td>\n",
              "      <td>0.075959</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>0.002041</td>\n",
              "      <td>0.992188</td>\n",
              "      <td>0.951172</td>\n",
              "      <td>0.939941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.849609</td>\n",
              "      <td>0.115765</td>\n",
              "      <td>72.125000</td>\n",
              "      <td>0.001540</td>\n",
              "      <td>0.973633</td>\n",
              "      <td>0.979980</td>\n",
              "      <td>0.895996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.974121</td>\n",
              "      <td>0.013997</td>\n",
              "      <td>76.500000</td>\n",
              "      <td>0.002840</td>\n",
              "      <td>0.996094</td>\n",
              "      <td>0.991211</td>\n",
              "      <td>0.986816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.924805</td>\n",
              "      <td>0.074373</td>\n",
              "      <td>82.125000</td>\n",
              "      <td>0.003157</td>\n",
              "      <td>0.991211</td>\n",
              "      <td>0.955078</td>\n",
              "      <td>0.978516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>2.442139</td>\n",
              "      <td>0.604545</td>\n",
              "      <td>63.875000</td>\n",
              "      <td>0.005754</td>\n",
              "      <td>0.930664</td>\n",
              "      <td>0.729004</td>\n",
              "      <td>0.782471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.890137</td>\n",
              "      <td>0.092661</td>\n",
              "      <td>52.250000</td>\n",
              "      <td>0.001735</td>\n",
              "      <td>0.996582</td>\n",
              "      <td>0.934570</td>\n",
              "      <td>0.958984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.401306</td>\n",
              "      <td>0.624909</td>\n",
              "      <td>49.375000</td>\n",
              "      <td>0.002870</td>\n",
              "      <td>0.977539</td>\n",
              "      <td>0.624939</td>\n",
              "      <td>0.798828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.825195</td>\n",
              "      <td>0.154224</td>\n",
              "      <td>62.625000</td>\n",
              "      <td>0.002436</td>\n",
              "      <td>0.986328</td>\n",
              "      <td>0.928711</td>\n",
              "      <td>0.910156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>2.778809</td>\n",
              "      <td>0.191046</td>\n",
              "      <td>61.625000</td>\n",
              "      <td>0.008588</td>\n",
              "      <td>0.978516</td>\n",
              "      <td>0.920898</td>\n",
              "      <td>0.879395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>2.697754</td>\n",
              "      <td>0.146664</td>\n",
              "      <td>61.125000</td>\n",
              "      <td>0.004994</td>\n",
              "      <td>0.969238</td>\n",
              "      <td>0.887207</td>\n",
              "      <td>0.841309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.806152</td>\n",
              "      <td>0.186064</td>\n",
              "      <td>65.125000</td>\n",
              "      <td>0.002408</td>\n",
              "      <td>0.981934</td>\n",
              "      <td>0.895996</td>\n",
              "      <td>0.928223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.938477</td>\n",
              "      <td>0.063735</td>\n",
              "      <td>54.625000</td>\n",
              "      <td>0.002010</td>\n",
              "      <td>0.995117</td>\n",
              "      <td>0.972168</td>\n",
              "      <td>0.971191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.779785</td>\n",
              "      <td>0.243963</td>\n",
              "      <td>68.375000</td>\n",
              "      <td>0.002814</td>\n",
              "      <td>0.973633</td>\n",
              "      <td>0.907227</td>\n",
              "      <td>0.898926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>2.685547</td>\n",
              "      <td>0.181342</td>\n",
              "      <td>60.250000</td>\n",
              "      <td>0.004406</td>\n",
              "      <td>0.990723</td>\n",
              "      <td>0.785156</td>\n",
              "      <td>0.909668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>2.851074</td>\n",
              "      <td>0.126360</td>\n",
              "      <td>65.125000</td>\n",
              "      <td>0.004087</td>\n",
              "      <td>0.991211</td>\n",
              "      <td>0.960449</td>\n",
              "      <td>0.899414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.913574</td>\n",
              "      <td>0.027418</td>\n",
              "      <td>58.125000</td>\n",
              "      <td>0.002803</td>\n",
              "      <td>0.996582</td>\n",
              "      <td>0.931152</td>\n",
              "      <td>0.985840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>2.140015</td>\n",
              "      <td>0.419907</td>\n",
              "      <td>55.250000</td>\n",
              "      <td>0.011289</td>\n",
              "      <td>0.914551</td>\n",
              "      <td>0.524292</td>\n",
              "      <td>0.701172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>2.701172</td>\n",
              "      <td>0.133500</td>\n",
              "      <td>56.250000</td>\n",
              "      <td>0.007143</td>\n",
              "      <td>0.989258</td>\n",
              "      <td>0.758789</td>\n",
              "      <td>0.953125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>2.538086</td>\n",
              "      <td>0.289979</td>\n",
              "      <td>68.500000</td>\n",
              "      <td>0.013680</td>\n",
              "      <td>0.947266</td>\n",
              "      <td>0.861328</td>\n",
              "      <td>0.729492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>2.888672</td>\n",
              "      <td>0.107566</td>\n",
              "      <td>63.875000</td>\n",
              "      <td>0.005470</td>\n",
              "      <td>0.989258</td>\n",
              "      <td>0.966797</td>\n",
              "      <td>0.932617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>2.917480</td>\n",
              "      <td>0.048089</td>\n",
              "      <td>89.375000</td>\n",
              "      <td>0.005465</td>\n",
              "      <td>0.980957</td>\n",
              "      <td>0.967285</td>\n",
              "      <td>0.969238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.949219</td>\n",
              "      <td>0.029157</td>\n",
              "      <td>73.250000</td>\n",
              "      <td>0.003563</td>\n",
              "      <td>0.995605</td>\n",
              "      <td>0.966309</td>\n",
              "      <td>0.987305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.606445</td>\n",
              "      <td>0.479462</td>\n",
              "      <td>55.750000</td>\n",
              "      <td>0.002503</td>\n",
              "      <td>0.971191</td>\n",
              "      <td>0.818848</td>\n",
              "      <td>0.816406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>2.770020</td>\n",
              "      <td>0.264123</td>\n",
              "      <td>49.500000</td>\n",
              "      <td>0.012366</td>\n",
              "      <td>0.979980</td>\n",
              "      <td>0.878906</td>\n",
              "      <td>0.911133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>2.959473</td>\n",
              "      <td>0.023245</td>\n",
              "      <td>53.750000</td>\n",
              "      <td>0.003859</td>\n",
              "      <td>0.992188</td>\n",
              "      <td>0.989258</td>\n",
              "      <td>0.978027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>2.723389</td>\n",
              "      <td>0.226148</td>\n",
              "      <td>55.125000</td>\n",
              "      <td>0.009740</td>\n",
              "      <td>0.981934</td>\n",
              "      <td>0.846436</td>\n",
              "      <td>0.895020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>2.452881</td>\n",
              "      <td>0.323543</td>\n",
              "      <td>76.250000</td>\n",
              "      <td>0.007582</td>\n",
              "      <td>0.946289</td>\n",
              "      <td>0.738525</td>\n",
              "      <td>0.768066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>2.780273</td>\n",
              "      <td>0.109250</td>\n",
              "      <td>53.125000</td>\n",
              "      <td>0.004648</td>\n",
              "      <td>0.980957</td>\n",
              "      <td>0.916016</td>\n",
              "      <td>0.883301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>2.321533</td>\n",
              "      <td>0.380398</td>\n",
              "      <td>40.375000</td>\n",
              "      <td>0.050358</td>\n",
              "      <td>0.979004</td>\n",
              "      <td>0.500488</td>\n",
              "      <td>0.842041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>2.793945</td>\n",
              "      <td>0.139454</td>\n",
              "      <td>50.875000</td>\n",
              "      <td>0.004300</td>\n",
              "      <td>0.988281</td>\n",
              "      <td>0.854492</td>\n",
              "      <td>0.951172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>2.597656</td>\n",
              "      <td>0.096115</td>\n",
              "      <td>60.625000</td>\n",
              "      <td>0.008013</td>\n",
              "      <td>0.978027</td>\n",
              "      <td>0.729492</td>\n",
              "      <td>0.890137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>2.806641</td>\n",
              "      <td>0.208662</td>\n",
              "      <td>52.375000</td>\n",
              "      <td>0.007477</td>\n",
              "      <td>0.985352</td>\n",
              "      <td>0.901855</td>\n",
              "      <td>0.919434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>2.394531</td>\n",
              "      <td>0.432016</td>\n",
              "      <td>41.375000</td>\n",
              "      <td>0.011934</td>\n",
              "      <td>0.914062</td>\n",
              "      <td>0.826660</td>\n",
              "      <td>0.653809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>2.834961</td>\n",
              "      <td>0.163153</td>\n",
              "      <td>32.500000</td>\n",
              "      <td>0.013250</td>\n",
              "      <td>0.998047</td>\n",
              "      <td>0.896973</td>\n",
              "      <td>0.939941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>2.657227</td>\n",
              "      <td>0.209972</td>\n",
              "      <td>45.500000</td>\n",
              "      <td>0.009835</td>\n",
              "      <td>0.972168</td>\n",
              "      <td>0.835449</td>\n",
              "      <td>0.849609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.783691</td>\n",
              "      <td>0.360108</td>\n",
              "      <td>66.375000</td>\n",
              "      <td>0.003500</td>\n",
              "      <td>0.986816</td>\n",
              "      <td>0.877441</td>\n",
              "      <td>0.919434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>2.748047</td>\n",
              "      <td>0.139332</td>\n",
              "      <td>50.750000</td>\n",
              "      <td>0.003262</td>\n",
              "      <td>0.991211</td>\n",
              "      <td>0.838867</td>\n",
              "      <td>0.917969</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=50, training_loss=0.00021147593189198234, metrics={'train_runtime': 852.9223, 'train_samples_per_second': 0.469, 'train_steps_per_second': 0.059, 'total_flos': 0.0, 'train_loss': 0.00021147593189198234})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer = GRPOTrainer(\n",
        "    model = model,\n",
        "    processing_class = tokenizer,\n",
        "    reward_funcs = [\n",
        "        pi_concise,\n",
        "        pi_coverage,\n",
        "        pi_standalone,\n",
        "    ],\n",
        "    args = training_args,\n",
        "    train_dataset = dataset,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUbluAAhD0Lg"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "Now let's try the model we just trained! First, let's first try the model without any GRPO trained:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "cbcc603580c844df9bc9a30bf902b05d",
            "f2f6fd5ecfa747b98d1943e7dc901266",
            "31048ef332954877b08a7e759e123255",
            "2768fcdbac814d6486904dc2bd41b4b9",
            "0e76f2a644d740ed9ca6f9934e055755",
            "abeb6ed58cd84cf08f43e9e7a2258c98",
            "26d0d5c6fdc14c3d98f343bfcfadeb4f",
            "9879ef3326454376bda2b62befed6575",
            "2eb3210c62f44b679b7eb59d35db93d1",
            "ed88715cfe11469ea696a91c08323683",
            "bfeacdf918204349a5eaa58f155c8bb0"
          ]
        },
        "id": "IqzsdZzeDM_m",
        "outputId": "6c185b6c-e9e0-405b-ac69-25eac7fa72ec"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cbcc603580c844df9bc9a30bf902b05d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The OP is concerned that they may have ruined their chances of a serious relationship by sleeping with their friend, who is now suggesting a casual relationship. They slept with the guy after a few hangouts, and are unsure if he wants a serious or casual relationship.'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "post = \"\"\"SUBREDDIT: r/relationships\n",
        "\n",
        "TITLE: Me [19 F] with my friend [19 M], not sure if I may have messed things up already.\n",
        "\n",
        "POST: Hello hello everybody. I hope this isn't too trivial of a question to ask on here, but I've been feeling a bit out of my depth when it comes to this situation (I've had only one relationship before, and for many reasons, it was out of the ordinary).\n",
        "\n",
        "Okay! So, a couple of weeks ago, I started talking to this guy on Facebook, through a student group that we were both part of. I thought he was sort of cute, so I sent him a PM just to talk, etc, etc. We're both transfer students at the same school, so I knew that we could eventually meet in person once we both moved on-campus. So, we did, and we hung out maybe twice, just as friends.\n",
        "\n",
        "Okay. So, everything is going pretty well. We talk over Facebook and Snapchat, whatever. So, Saturday night, I was just hanging out with people and kind of being bored, when I got a Snapchat from him asking what I was doing. I asked if he wanted to hang out, so we did.\n",
        "\n",
        "We ended up smoking pot (the first time for me, ever), and sort of just wandering around. Eventually we ended up back at his dorm room, where high me decided to just go for it, and I came on to him pretty strongly. It worked out for me (luckily, otherwise things would have been really super awkward), and we ended up messing around but not having sex.\n",
        "\n",
        "Yesterday, however, I ended up going to hang out with him again, and this time we did sleep together. Afterward, we kind of discussed what we were going to do, and he just said that he wanted to \"play it by ear\" and not slap any labels on anything. I'm wondering if this means that he wants a fwb-type situation, or if he might actually be interested in me. The way I've been acting is extremely out of character for me, and I am not interested in having a fuck buddy. I like him, and I would be very interested in maybe seeing where things go, but I'm worried that I may have ruined my chances of a relationship by sleeping with him already.\n",
        "\n",
        "TL;DR:\n",
        "\"\"\"\n",
        "\n",
        "text = tokenizer.apply_chat_template(\n",
        "    [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\"role\": \"user\", \"content\": post},\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True,\n",
        ")\n",
        "\n",
        "from vllm import SamplingParams\n",
        "\n",
        "sampling_params = SamplingParams(\n",
        "    temperature=0.4,\n",
        "    top_p=0.95,\n",
        "    max_tokens=1024,\n",
        ")\n",
        "output = (\n",
        "    model.fast_generate(\n",
        "        [text],\n",
        "        sampling_params=sampling_params,\n",
        "        lora_request=None,\n",
        "    )[0]\n",
        "    .outputs[0]\n",
        "    .text\n",
        ")\n",
        "\n",
        "output"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e76f2a644d740ed9ca6f9934e055755": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "26d0d5c6fdc14c3d98f343bfcfadeb4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2768fcdbac814d6486904dc2bd41b4b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed88715cfe11469ea696a91c08323683",
            "placeholder": "​",
            "style": "IPY_MODEL_bfeacdf918204349a5eaa58f155c8bb0",
            "value": " 1/1 [00:01&lt;00:00,  1.68s/it, est. speed input: 333.85 toks/s, output: 31.48 toks/s]"
          }
        },
        "2eb3210c62f44b679b7eb59d35db93d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31048ef332954877b08a7e759e123255": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9879ef3326454376bda2b62befed6575",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2eb3210c62f44b679b7eb59d35db93d1",
            "value": 1
          }
        },
        "9879ef3326454376bda2b62befed6575": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abeb6ed58cd84cf08f43e9e7a2258c98": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfeacdf918204349a5eaa58f155c8bb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbcc603580c844df9bc9a30bf902b05d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2f6fd5ecfa747b98d1943e7dc901266",
              "IPY_MODEL_31048ef332954877b08a7e759e123255",
              "IPY_MODEL_2768fcdbac814d6486904dc2bd41b4b9"
            ],
            "layout": "IPY_MODEL_0e76f2a644d740ed9ca6f9934e055755"
          }
        },
        "ed88715cfe11469ea696a91c08323683": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2f6fd5ecfa747b98d1943e7dc901266": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abeb6ed58cd84cf08f43e9e7a2258c98",
            "placeholder": "​",
            "style": "IPY_MODEL_26d0d5c6fdc14c3d98f343bfcfadeb4f",
            "value": "Processed prompts: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
