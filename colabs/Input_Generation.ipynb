{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/withpi/cookbook-withpi/blob/main/colabs/Input_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://withpi.ai\"><img src=\"https://play.withpi.ai/logo/logoFullBlack.svg\" width=\"240\"></a>\n",
        "\n",
        "<a href=\"https://code.withpi.ai\"><font size=\"4\">Documentation</font></a>\n",
        "\n",
        "<a href=\"https://build.withpi.ai\"><font size=\"4\">Copilot</font></a>"
      ],
      "metadata": {
        "id": "pi-masthead"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bwm4tjdnedp6"
      },
      "source": [
        "# Input Generation\n",
        "\n",
        "Many techniques require input data to drives evaluation and training, but getting high-quality data can be painful and expensive.\n",
        "\n",
        "Generating this data with AI support can give you a higher quality set with much lower effort."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install and initialize SDK\n",
        "\n",
        "You'll need a `WITHPI_API_KEY` from https://build.withpi.ai/account.  Add it to your notebook secrets (the key symbol) on the left.\n",
        "\n",
        "Run the cell below to install packages and load the SDK"
      ],
      "metadata": {
        "id": "pi-setup-markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi-setup"
      },
      "outputs": [],
      "execution_count": null,
      "source": [
        "%%capture\n",
        "\n",
        "%pip install withpi withpi-utils datasets tqdm litellm pandas numpy\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from withpi import PiClient\n",
        "\n",
        "# Load the notebook secret into the environment so the Pi Client can access it.\n",
        "os.environ[\"WITHPI_API_KEY\"] = userdata.get('WITHPI_API_KEY')\n",
        "\n",
        "pi = PiClient()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1FAoBqU7dwf"
      },
      "source": [
        "## Generate an Input Set\n",
        "\n",
        "Given this structured description, let's build a Dataset containing a bunch of plausible moral lessons that could be used to exercise our `Aesop AI` toy application."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NpCZhP6exgI"
      },
      "outputs": [],
      "source": [
        "data_generation_status = pi.data.generate.start_job(\n",
        "    application_description=\"\"\"\n",
        "Write a children's story in the style of Aesop's Fables teaching a life lesson\n",
        "specified by the user. Provide just the story with no extra content.\n",
        "\"\"\",\n",
        "    num_inputs_to_generate=12,\n",
        "    seeds=[],\n",
        "    batch_size=3,\n",
        "    num_shots=3,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktYlEezB236H"
      },
      "source": [
        "## Stream results\n",
        "\n",
        "The stream utility will yield data as it is generated, while printing status messages.  The below snippet will intersperse the two."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_cX91PLz7S7",
        "outputId": "26977012-f1e5-4ac9-e859-6f0117dd25f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LAUNCHING\n",
            "RUNNING\n",
            "[INFO] Generating 10 seeds as they are not provided.\n",
            "[OUTPUT] - Create a fable about the importance of teamwork.\n",
            "[OUTPUT] - Write a fable that teaches children why patience is important.\n",
            "[OUTPUT] - Generate a fable showing the consequences of dishonesty.\n",
            "[OUTPUT] - Tell a story about a squirrel learning the value of saving for the future.\n",
            "[OUTPUT] - Give a fable that illustrates why kindness leads to better friendships.\n",
            "[OUTPUT] - Write a fable about a young fox who learns not to judge others by appearances.\n",
            "[OUTPUT] - Create a story showing how greed can lead to unhappiness.\n",
            "[OUTPUT] - Tell a fable about a group of animals who learn the value of listening to advice.\n",
            "[OUTPUT] - Compose a fable about a bird who discovers the rewards of hard work.\n",
            "[OUTPUT] - Create a fable teaching that small acts of kindness can make a big difference.\n",
            "[INFO] Yielding generated 10 seeds\n",
            "[INFO] Data Generation Ongoing => Good Inputs: 10/12. Bad Inputs: 0. Similar Inputs: 0\n",
            "[INFO] Generated themes: ['Ethical Lessons', 'Animal Adventures', 'Moral Dilemmas', 'Friendship and Trust', 'Nature and Environment', 'Teamwork and Cooperation', 'Courage and Bravery', 'Kindness and Generosity', 'Wisdom and Foolishness', 'Perseverance and Determination']\n",
            "[INFO] Parallel generation batches are being launched\n",
            "[GENERATOR-0] Starting generator worker\n",
            "[INFO] Using selected theme: 'Perseverance and Determination' for this batch of generation\n",
            "[GENERATOR-1] Starting generator worker\n",
            "[INFO] Using selected theme: 'Kindness and Generosity' for this batch of generation\n",
            "[GENERATOR-2] Starting generator worker\n",
            "[INFO] Using selected theme: 'Perseverance and Determination' for this batch of generation\n",
            "[CRITIC-0] Starting critic worker\n",
            "[CRITIC-1] Starting critic worker\n",
            "[CRITIC-2] Starting critic worker\n",
            "[CRITIC-3] Starting critic worker\n",
            "[CRITIC-4] Starting critic worker\n",
            "[CRITIC-5] Starting critic worker\n",
            "[INFO] Using No theme for this batch of generation\n",
            "[INFO] Using No theme for this batch of generation\n",
            "[INFO] Using selected theme: 'Wisdom and Foolishness' for this batch of generation\n",
            "[INFO] Generation LLM temperature fixed or updated to 1.0\n",
            "[INFO] _gen_batches_triggered: 6 | _critique_batches_completed: 1\n",
            "[INFO] Progress=> Good: 13/12 Bad: 0 Similar: 0\n",
            "[INFO] Data Generation Complete => Good Inputs: 13. Bad Inputs: 0. Similar Inputs: 0\n",
            "[INFO] Data Generation Complete => Good Inputs: 13. Bad Inputs: 0. Similar Inputs: 0\n",
            "[OUTPUT] - Create a fable that illustrates the value of thinking before acting.\n",
            "[OUTPUT] - Tell a fable about a wise old owl who teaches a boastful rabbit a lesson about humility.\n",
            "[OUTPUT] - Write a fable where a clever tortoise learns the importance of sharing with others.\n",
            "[GENERATOR-2] Generator worker exiting\n",
            "[CRITIC-3] Critic worker exiting\n",
            "[CRITIC-4] Critic worker exiting\n",
            "[CRITIC-5] Critic worker exiting\n",
            "[CRITIC-0] Critic worker exiting\n",
            "[CRITIC-1] Critic worker exiting\n",
            "[CRITIC-2] Critic worker exiting\n",
            "DONE\n"
          ]
        }
      ],
      "source": [
        "from withpi_utils.jobs import stream\n",
        "\n",
        "for data in stream(pi.data.generate, data_generation_status):\n",
        "  print(f\"[OUTPUT] - {data}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLi5JRNz_IUd"
      },
      "source": [
        "## Take a look at the returned data\n",
        "\n",
        "Take a look at the returned inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDOM8UIA96M9",
        "outputId": "49008b82-3285-4e2d-d294-36ef943b328f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Printing all the generated inputs below...\n",
            "\n",
            "Create a fable about the importance of teamwork.\n",
            "Write a fable that teaches children why patience is important.\n",
            "Generate a fable showing the consequences of dishonesty.\n",
            "Tell a story about a squirrel learning the value of saving for the future.\n",
            "Give a fable that illustrates why kindness leads to better friendships.\n",
            "Write a fable about a young fox who learns not to judge others by appearances.\n",
            "Create a story showing how greed can lead to unhappiness.\n",
            "Tell a fable about a group of animals who learn the value of listening to advice.\n",
            "Compose a fable about a bird who discovers the rewards of hard work.\n",
            "Create a fable teaching that small acts of kindness can make a big difference.\n",
            "Create a fable that illustrates the value of thinking before acting.\n",
            "Tell a fable about a wise old owl who teaches a boastful rabbit a lesson about humility.\n",
            "Write a fable where a clever tortoise learns the importance of sharing with others.\n"
          ]
        }
      ],
      "source": [
        "data_generation_status = pi.data.generate.retrieve(job_id=data_generation_status.job_id)\n",
        "\n",
        "# Print all the data now that the job is complete.\n",
        "if data_generation_status.state not in [\"ERROR\", \"DONE\"]:\n",
        "  print(\"Please wait for the job to finish and then run this cell again...\")\n",
        "else:\n",
        "    if data_generation_status.state == \"DONE\":\n",
        "        print(\"Printing all the generated inputs below...\\n\")\n",
        "        assert data_generation_status.data is not None\n",
        "        for input in data_generation_status.data:\n",
        "            print(input)\n",
        "    else:\n",
        "        print(\"Job ended in error\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jT7s_nuJsHbM"
      },
      "source": [
        "## Next Steps\n",
        "\n",
        "You can take this input set and use it to drive your evaluation or training workflows as you see fit."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}