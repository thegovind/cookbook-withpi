{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/withpi/cookbook-withpi/blob/main/colabs/Langfuse_PI_Integration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://withpi.ai\"><img src=\"https://play.withpi.ai/logo/logoFullBlack.svg\" width=\"240\"></a>\n",
        "\n",
        "<a href=\"https://code.withpi.ai\"><font size=\"4\">Documentation</font></a>\n",
        "\n",
        "<a href=\"https://build.withpi.ai\"><font size=\"4\">Copilot</font></a>"
      ],
      "metadata": {
        "id": "pi-masthead"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Pi-Scorer](https://build.withpi.ai) offers an alternative to LLM-as-a-judge with several advantages:\n",
        "\n",
        "* Significantly faster\n",
        "\n",
        "* Highly consistent \u2014 always returns the same score for the same inputs\n",
        "\n",
        "* Eliminates the need for prompt tuning or adjustments"
      ],
      "metadata": {
        "id": "eiR5tdXsVdNk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PONlf847Xp-A"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install langfuse openai langchain_openai langchain datasets --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAquPGo3X8hg"
      },
      "outputs": [],
      "source": [
        "# @title Setup API Keys\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Get keys for your project from the project settings page\n",
        "# https://cloud.langfuse.com\n",
        "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = userdata.get(\"LANGFUSE_PUBLIC_KEY\")\n",
        "os.environ[\"LANGFUSE_SECRET_KEY\"] = userdata.get(\"LANGFUSE_SECRET_KEY\")\n",
        "# os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\" # \ud83c\uddea\ud83c\uddfa EU region\n",
        "os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\" # \ud83c\uddfa\ud83c\uddf8 US region\n",
        "\n",
        "# Your openai key\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Get PI API key: https://build.withpi.ai/account/keys\n",
        "os.environ[\"WITHPI_API_KEY\"] = userdata.get('WITHPI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load a blog-post dataset to Langfuse\n",
        "\n",
        "from datasets import load_dataset\n",
        "from langfuse import Langfuse\n",
        "\n",
        "# Load data from Huggingface\n",
        "ds = load_dataset(\"withpi/mlmastery_com_blogs_condensed\", split=\"train\")\n",
        "topics = ds[\"topic\"][:5]\n",
        "data = [{\"input\": topic} for topic in topics]\n",
        "display(data)\n",
        "\n",
        "# Upload to Langfuse\n",
        "langfuse = Langfuse()\n",
        "langfuse.create_dataset(name=\"blog_posts\")\n",
        "for item in data:\n",
        "  langfuse.create_dataset_item(\n",
        "      dataset_name=\"blog_posts\",\n",
        "      # any python object or value\n",
        "      input=item[\"input\"]\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "03cwaJ_SAeVJ",
        "outputId": "2b639a74-8d39-4c7b-b825-0e1f6373f721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[{'input': 'Tips for beginners to get started with deep learning, including mastering machine learning fundamentals, choosing a framework, understanding neural network architectures, starting with simple projects, and practicing regularly while engaging with the community.'},\n",
              " {'input': 'The topic of this blog post is: \"Understanding the Data Science Mind Map: A comprehensive guide to essential Python packages for data preparation, visualization, and statistical analysis, with an emphasis on storytelling in data science.\"'},\n",
              " {'input': 'The 5 Most Influential Machine Learning Research Papers of 2024 and Their Contributions to AI Advancement'},\n",
              " {'input': 'Cross-validation techniques for comprehensive model evaluation beyond simple train-test splits'},\n",
              " {'input': 'Creating an effective machine learning portfolio that demonstrates practical skills and helps land job opportunities in the competitive ML industry.'}]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title My custom application setup: blog-post generator\n",
        "\n",
        "from langfuse.openai import openai\n",
        "from langfuse.decorators import observe, langfuse_context\n",
        "\n",
        "@observe()\n",
        "def run_my_custom_llm_app(input, system_prompt):\n",
        "  messages = [\n",
        "      {\"role\":\"system\", \"content\": system_prompt},\n",
        "      {\"role\":\"user\", \"content\": input}\n",
        "  ]\n",
        "\n",
        "  completion = openai.chat.completions.create(\n",
        "      model=\"gpt-4o-mini\",\n",
        "      messages=messages\n",
        "  ).choices[0].message.content\n",
        "\n",
        "  return completion"
      ],
      "metadata": {
        "id": "lgLGstfrBxjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Pi-Scorer Setup\n",
        "\n",
        "import os\n",
        "import requests\n",
        "\n",
        "PI_API_URL = \"https://api.withpi.ai/v1/scoring_system/score\"\n",
        "HEADERS = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"x-api-key\": os.environ.get(\"WITHPI_API_KEY\"),\n",
        "}\n",
        "\n",
        "def get_score(input: str, output: str, question: str):\n",
        "    payload = {\n",
        "      \"llm_input\": input,\n",
        "      \"llm_output\": output,\n",
        "      \"scoring_spec\": [{\"question\": question}]\n",
        "    }\n",
        "    response = requests.post(PI_API_URL, headers=HEADERS, json=payload)\n",
        "    pi_score = response.json()\n",
        "    return pi_score[\"total_score\"]"
      ],
      "metadata": {
        "id": "szKYrvl8CT9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Setup Langfuse experiment\n",
        "\n",
        "def run_experiment(experiment_name, system_prompt):\n",
        "  dataset = langfuse.get_dataset(\"blog_posts\")\n",
        "\n",
        "  for item in dataset.items:\n",
        "    # item.observe() returns a trace_id that can be used to add custom evaluations later\n",
        "    # it also automatically links the trace to the experiment run\n",
        "    with item.observe(run_name=experiment_name) as trace_id:\n",
        "\n",
        "      # run application, pass input and system prompt\n",
        "      output = run_my_custom_llm_app(item.input, system_prompt)\n",
        "\n",
        "      # optional: add custom evaluation results to the experiment trace\n",
        "      # we use the previously created example evaluation function\n",
        "      langfuse.score(\n",
        "        trace_id=trace_id,\n",
        "        name=\"conclusion\",\n",
        "        value=get_score(item.input, output, question=\"Does the post have a conclusion section?\")\n",
        "      )\n",
        "      langfuse.score(\n",
        "        trace_id=trace_id,\n",
        "        name=\"pitfall\",\n",
        "        value=get_score(item.input, output, question=\"Does the post call out potential pitfalls or common mistakes?\")\n",
        "      )"
      ],
      "metadata": {
        "id": "1jH5xDNnDbha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run a Langfuse experiment\n",
        "\n",
        "from langfuse.decorators import langfuse_context\n",
        "\n",
        "run_experiment(\n",
        "    experiment_name=\"simple_prompt\",\n",
        "    system_prompt=\"\"\"You are a specialized blog post writer. Given a topic, write a technical blog post. Here are specific instructions:\n",
        "- Make sure that the blog is approximately under 500 words\n",
        "- The blog should be technical in nature with clear instructions\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# Assert that all events were sent to the Langfuse API\n",
        "langfuse_context.flush()\n",
        "langfuse.flush()"
      ],
      "metadata": {
        "id": "pNCSv9LMEp7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Langfuse dataset screenshot.\n",
        "![Result](https://raw.githubusercontent.com/withpi/cookbook-withpi/main/colabs/Langfuse_screenshot.png)"
      ],
      "metadata": {
        "id": "vyi_lM0nXjao"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}