{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/withpi/cookbook-withpi/blob/main/colabs/Langsmith_PI_Integration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://withpi.ai\"><img src=\"https://play.withpi.ai/logo/logoFullBlack.svg\" width=\"240\"></a>\n",
        "\n",
        "<a href=\"https://code.withpi.ai\"><font size=\"4\">Documentation</font></a>\n",
        "\n",
        "<a href=\"https://build.withpi.ai\"><font size=\"4\">Copilot</font></a>"
      ],
      "metadata": {
        "id": "pi-masthead"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Pi-Scorer](https://build.withpi.ai) offers an alternative to LLM-as-a-judge with several advantages:\n",
        "\n",
        "* Significantly faster\n",
        "\n",
        "* Highly consistent \u2014 always returns the same score for the same inputs\n",
        "\n",
        "* Eliminates the need for prompt tuning or adjustments"
      ],
      "metadata": {
        "id": "eiR5tdXsVdNk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PONlf847Xp-A"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install -U langsmith openevals openai datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAquPGo3X8hg"
      },
      "outputs": [],
      "source": [
        "# @title Setup API Keys\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Get keys for your project from the project settings page\n",
        "# https://smith.langchain.com/\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = userdata.get(\"LANGSMITH_API_KEY\")\n",
        "\n",
        "# Your openai key\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Get PI API key: https://build.withpi.ai/account/keys\n",
        "os.environ[\"WITHPI_API_KEY\"] = userdata.get('WITHPI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load a blog-post dataset to Langsmith\n",
        "\n",
        "from datasets import load_dataset\n",
        "from langsmith import Client\n",
        "\n",
        "# Load data from Huggingface\n",
        "ds = load_dataset(\"withpi/mlmastery_com_blogs_condensed\", split=\"train\")\n",
        "topics = ds[\"topic\"][:5]\n",
        "examples = [{\"inputs\": {\"topic\": topic}} for topic in topics]\n",
        "display(examples)\n",
        "\n",
        "# Upload to Langsmith\n",
        "langsmith_client = Client()\n",
        "dataset = langsmith_client.create_dataset(dataset_name=\"blog_posts\", description=\"Blog post generator.\")\n",
        "langsmith_client.create_examples(dataset_id=dataset.id, examples=examples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "03cwaJ_SAeVJ",
        "outputId": "b017c83c-e9c8-4b0c-8aa8-7f5ad11c3043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[{'inputs': {'topic': 'Tips for beginners to get started with deep learning, including mastering machine learning fundamentals, choosing a framework, understanding neural network architectures, starting with simple projects, and practicing regularly while engaging with the community.'}},\n",
              " {'inputs': {'topic': 'The topic of this blog post is: \"Understanding the Data Science Mind Map: A comprehensive guide to essential Python packages for data preparation, visualization, and statistical analysis, with an emphasis on storytelling in data science.\"'}},\n",
              " {'inputs': {'topic': 'The 5 Most Influential Machine Learning Research Papers of 2024 and Their Contributions to AI Advancement'}},\n",
              " {'inputs': {'topic': 'Cross-validation techniques for comprehensive model evaluation beyond simple train-test splits'}},\n",
              " {'inputs': {'topic': 'Creating an effective machine learning portfolio that demonstrates practical skills and helps land job opportunities in the competitive ML industry.'}}]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'example_ids': ['453b9839-e37b-4c38-a50d-412252eae45c',\n",
              "  '377f5d49-a258-4cf2-b578-a0e4fd2debc5',\n",
              "  '6f2aecf0-b72e-4875-be32-08d4c9f0a295',\n",
              "  '6fa7f560-f011-44d7-82da-7a3f0ec93a82',\n",
              "  'b3588b58-8b79-4f54-bc6c-42b1109fdad0'],\n",
              " 'count': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title My custom application setup: blog-post generator\n",
        "\n",
        "from langsmith import wrappers\n",
        "from openai import OpenAI\n",
        "\n",
        "# Wrap the OpenAI client for LangSmith tracing\n",
        "openai_client = wrappers.wrap_openai(OpenAI())\n",
        "\n",
        "# Define the application logic you want to evaluate inside a target function\n",
        "# The SDK will automatically send the inputs from the dataset to your target function\n",
        "def target(inputs: dict) -> dict:\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"\"\"You are a specialized blog post writer. Given a topic, write a technical blog post. Here are specific instructions:\n",
        "- Make sure that the blog is approximately under 500 words\n",
        "- The blog should be technical in nature with clear instructions\n",
        "\"\"\"},\n",
        "            {\"role\": \"user\", \"content\": inputs[\"topic\"]},\n",
        "        ],\n",
        "    )\n",
        "    return { \"blogpost\": response.choices[0].message.content.strip() }"
      ],
      "metadata": {
        "id": "lgLGstfrBxjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Pi-Scorer Setup\n",
        "\n",
        "import os\n",
        "import requests\n",
        "\n",
        "PI_API_URL = \"https://api.withpi.ai/v1/scoring_system/score\"\n",
        "HEADERS = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"x-api-key\": os.environ.get(\"WITHPI_API_KEY\"),\n",
        "}\n",
        "\n",
        "def get_score(input: str, output: str, question: str):\n",
        "    payload = {\n",
        "      \"llm_input\": input,\n",
        "      \"llm_output\": output,\n",
        "      \"scoring_spec\": [{\"question\": question}]\n",
        "    }\n",
        "    response = requests.post(PI_API_URL, headers=HEADERS, json=payload)\n",
        "    pi_score = response.json()\n",
        "    return pi_score[\"total_score\"]\n",
        "\n",
        "def make_evaluator(key, question):\n",
        "    def evaluator(inputs, outputs):\n",
        "        return {\n",
        "            \"key\": key,\n",
        "            \"score\": get_score(inputs[\"topic\"], outputs[\"blogpost\"], question),\n",
        "        }\n",
        "    return evaluator\n",
        "\n",
        "conclusion_evaluator = make_evaluator(\n",
        "    \"conclusion\", \"Does the post have a conclusion section?\"\n",
        ")\n",
        "\n",
        "pitfall_evaluator = make_evaluator(\n",
        "    \"pitfall\", \"Does the post call out potential pitfalls or common mistakes?\"\n",
        ")"
      ],
      "metadata": {
        "id": "szKYrvl8CT9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run Langsmith evaluation\n",
        "\n",
        "experiment_results = langsmith_client.evaluate(\n",
        "    target,\n",
        "    data=\"blog_posts\",\n",
        "    evaluators=[\n",
        "        conclusion_evaluator,\n",
        "        pitfall_evaluator,\n",
        "    ],\n",
        "    experiment_prefix=\"blog_post_eval\",\n",
        "    max_concurrency=1,\n",
        ")"
      ],
      "metadata": {
        "id": "1jH5xDNnDbha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "See result at https://smith.langchain.com/public/ff72f973-5b38-4d91-a6fe-11960eb17448/d"
      ],
      "metadata": {
        "id": "KrtEhmBJDNpO"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}